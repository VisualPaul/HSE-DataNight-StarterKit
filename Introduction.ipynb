{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Практическое руководство по анализу данных\n",
    "\n",
    "Официальное название: \"Визуализация, машинное обучение и неструктурированные данные: практическое руководство\"\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Рабочее окружение: Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ноутбуки (тетрадки)\n",
    "\n",
    "- Разметка\n",
    "- Возможность вывода графиков, изображений и тд."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Редактирование python-файлов\n",
    "\n",
    "- Как создавать файлы\n",
    "- Идея: выносить сложные куски кода в python-модули, в ноутбуке оставлять эксперименты"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Работа в консоли\n",
    "\n",
    "- Вызов команд консоли из ноутбука: `!ls -l`\n",
    "- Использование терминала"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wget: missing URL\r\n",
      "Usage: wget [OPTION]... [URL]...\r\n",
      "\r\n",
      "Try `wget --help' for more options.\r\n"
     ]
    }
   ],
   "source": [
    "!wget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34mAI_challenge\u001b[m\u001b[m             Untitled2.ipynb          \u001b[34mdotascience\u001b[m\u001b[m\r\n",
      "\u001b[34mCG\u001b[m\u001b[m                       alarm_clock.py           \u001b[34mml_lab_2\u001b[m\u001b[m\r\n",
      "\u001b[34mEEG\u001b[m\u001b[m                      \u001b[34mbd_shad\u001b[m\u001b[m                  \u001b[34mmmkTest\u001b[m\u001b[m\r\n",
      "\u001b[34mHSE-DataNight-StarterKit\u001b[m\u001b[m \u001b[34mcg_tasks\u001b[m\u001b[m                 \u001b[34mreproducible-work\u001b[m\u001b[m\r\n",
      "Introduction.ipynb       \u001b[34mdeep_learning\u001b[m\u001b[m            \u001b[34mstress_prediction\u001b[m\u001b[m\r\n",
      "Untitled.ipynb           \u001b[34mdm-env\u001b[m\u001b[m                   \u001b[34mxgboost\u001b[m\u001b[m\r\n",
      "Untitled1.ipynb          \u001b[34mdota2\u001b[m\u001b[m\r\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tar: Option f requires an argument\r\n",
      "Usage:\r\n",
      "  List:    tar -tf <archive-filename>\r\n",
      "  Extract: tar -xf <archive-filename>\r\n",
      "  Create:  tar -cf <archive-filename> [filenames...]\r\n",
      "  Help:    tar --help\r\n"
     ]
    }
   ],
   "source": [
    "!tar xvf "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UnZip 5.52 of 28 February 2005, by Info-ZIP.  Maintained by C. Spieler.  Send\r\n",
      "bug reports using http://www.info-zip.org/zip-bug.html; see README for details.\r\n",
      "\r\n",
      "Usage: unzip [-Z] [-opts[modifiers]] file[.zip] [list] [-x xlist] [-d exdir]\r\n",
      "  Default action is to extract files in list, except those in xlist, to exdir;\r\n",
      "  file[.zip] may be a wildcard.  -Z => ZipInfo mode (\"unzip -Z\" for usage).\r\n",
      "\r\n",
      "  -p  extract files to pipe, no messages     -l  list files (short format)\r\n",
      "  -f  freshen existing files, create none    -t  test compressed archive data\r\n",
      "  -u  update files, create if necessary      -z  display archive comment\r\n",
      "  -x  exclude files that follow (in xlist)   -d  extract files into exdir\r\n",
      "\r\n",
      "modifiers:                                   -q  quiet mode (-qq => quieter)\r\n",
      "  -n  never overwrite existing files         -a  auto-convert any text files\r\n",
      "  -o  overwrite files WITHOUT prompting      -aa treat ALL files as text\r\n",
      "  -j  junk paths (do not make directories)   -v  be verbose/print version info\r\n",
      "  -C  match filenames case-insensitively     -L  make (some) names lowercase\r\n",
      "  -X  restore UID/GID info                   -V  retain VMS version numbers\r\n",
      "  -K  keep setuid/setgid/tacky permissions   -M  pipe through \"more\" pager\r\n",
      "Examples (see unzip.txt for more info):\r\n",
      "  unzip data1 -x joe   => extract all files except joe from zipfile data1.zip\r\n",
      "  unzip -p foo | more  => send contents of foo.zip via pipe into program more\r\n",
      "  unzip -fo foo ReadMe => quietly replace existing ReadMe if archive file newer\r\n"
     ]
    }
   ],
   "source": [
    "!unzip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Получение и работа с данными"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Табличные данные"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "URLError",
     "evalue": "<urlopen error no host given>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mURLError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-09c93b4f57ac>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'http://'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    260\u001b[0m     filepath_or_buffer, _, compression = get_filepath_or_buffer(filepath_or_buffer,\n\u001b[1;32m    261\u001b[0m                                                                 \u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 262\u001b[0;31m                                                                 compression=kwds.get('compression', None))\n\u001b[0m\u001b[1;32m    263\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'compression'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minferred_compression\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/common.pyc\u001b[0m in \u001b[0;36mget_filepath_or_buffer\u001b[0;34m(filepath_or_buffer, encoding, compression)\u001b[0m\n\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_url\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m         \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_urlopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcompression\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'infer'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m             \u001b[0mcontent_encoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreq\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheaders\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Content-Encoding'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36murlopen\u001b[0;34m(url, data, timeout, cafile, capath, cadefault, context)\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m         \u001b[0mopener\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_opener\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mopener\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0minstall_opener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, fullurl, data, timeout)\u001b[0m\n\u001b[1;32m    427\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mprocessor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprotocol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    428\u001b[0m             \u001b[0mmeth\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprocessor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmeth_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 429\u001b[0;31m             \u001b[0mreq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmeth\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    430\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    431\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_open\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/Cellar/python/2.7.10_2/Frameworks/Python.framework/Versions/2.7/lib/python2.7/urllib2.pyc\u001b[0m in \u001b[0;36mdo_request_\u001b[0;34m(self, request)\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0mhost\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhost\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1125\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mURLError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'no host given'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhas_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# POST\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mURLError\u001b[0m: <urlopen error no host given>"
     ]
    }
   ],
   "source": [
    "pandas.read_csv('http://')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "IOError",
     "evalue": "File  does not exist",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIOError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-8db7d2ceb4ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpandas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, dialect, compression, doublequote, escapechar, quotechar, quoting, skipinitialspace, lineterminator, header, index_col, names, prefix, skiprows, skipfooter, skip_footer, na_values, true_values, false_values, delimiter, converters, dtype, usecols, engine, delim_whitespace, as_recarray, na_filter, compact_ints, use_unsigned, low_memory, buffer_lines, warn_bad_lines, error_bad_lines, keep_default_na, thousands, comment, decimal, parse_dates, keep_date_col, dayfirst, date_parser, memory_map, float_precision, nrows, iterator, chunksize, verbose, encoding, squeeze, mangle_dupe_cols, tupleize_cols, infer_datetime_format, skip_blank_lines)\u001b[0m\n\u001b[1;32m    496\u001b[0m                     skip_blank_lines=skip_blank_lines)\n\u001b[1;32m    497\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 498\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    499\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    500\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    273\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    274\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 275\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    276\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mchunksize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'has_index_names'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    589\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 590\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    591\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    592\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_options_with_defaults\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m    729\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'c'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'c'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 731\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    732\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'python'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/parsers.pyc\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1101\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'allow_leading_cols'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex_col\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1103\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1105\u001b[0m         \u001b[0;31m# XXX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader.__cinit__ (pandas/parser.c:3246)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mpandas/parser.pyx\u001b[0m in \u001b[0;36mpandas.parser.TextReader._setup_parser_source (pandas/parser.c:6111)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mIOError\u001b[0m: File  does not exist"
     ]
    }
   ],
   "source": [
    "pandas.read_csv('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Визуализация точек на карте\n",
    "\n",
    "Вставить сюда пример с [камерами видеонаблюдения](http://nbviewer.jupyter.org/github/romovpa/pygeoplot/blob/master/ipynb/DemoMoscowCCTV.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Таблицы со станиц интернета"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "html5lib not found, please install it",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-78c194dbc4d2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;34m'https://en.wikipedia.org/w/index.php?search=Dow+Jones+Industrial+Average&title=Special%3ASearch&go=Go'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'class'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'wikitable'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# фильтруем только таблицы с данными\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;31m# делаем первую строчку — заголовком\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m )\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/html.pyc\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, tupleize_cols, thousands, encoding)\u001b[0m\n\u001b[1;32m    864\u001b[0m     \u001b[0m_validate_header_arg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    865\u001b[0m     return _parse(flavor, io, match, header, index_col, skiprows,\n\u001b[0;32m--> 866\u001b[0;31m                   parse_dates, tupleize_cols, thousands, attrs, encoding)\n\u001b[0m",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/html.pyc\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, header, index_col, skiprows, parse_dates, tupleize_cols, thousands, attrs, encoding)\u001b[0m\n\u001b[1;32m    716\u001b[0m     \u001b[0mretained\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    717\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mflav\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mflavor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 718\u001b[0;31m         \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_parser_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mflav\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    719\u001b[0m         \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mio\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcompiled_match\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    720\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/kirusha/PythonProjects/dm-env/lib/python2.7/site-packages/pandas/io/html.pyc\u001b[0m in \u001b[0;36m_parser_dispatch\u001b[0;34m(flavor)\u001b[0m\n\u001b[1;32m    661\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mflavor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'bs4'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'html5lib'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    662\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_HTML5LIB\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 663\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"html5lib not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    664\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0m_HAS_BS4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    665\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mImportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"BeautifulSoup4 (bs4) not found, please install it\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: html5lib not found, please install it"
     ]
    }
   ],
   "source": [
    "tables = pandas.read_html(\n",
    "    'https://en.wikipedia.org/w/index.php?search=Dow+Jones+Industrial+Average&title=Special%3ASearch&go=Go', \n",
    "    attrs={'class': 'wikitable'},  # фильтруем только таблицы с данными\n",
    "    header=0, # делаем первую строчку — заголовком\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Company</th>\n",
       "      <th>Exchange</th>\n",
       "      <th>Symbol</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Date Added</th>\n",
       "      <th>Notes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3M</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>MMM</td>\n",
       "      <td>Conglomerate</td>\n",
       "      <td>1976-08-09</td>\n",
       "      <td>as Minnesota Mining and Manufacturing</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>American Express</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>AXP</td>\n",
       "      <td>Consumer finance</td>\n",
       "      <td>1982-08-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apple</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>Consumer electronics</td>\n",
       "      <td>2015-03-19</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boeing</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>BA</td>\n",
       "      <td>Aerospace and defense</td>\n",
       "      <td>1987-03-12</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Caterpillar</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>CAT</td>\n",
       "      <td>Construction and mining equipment</td>\n",
       "      <td>1991-05-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chevron</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>CVX</td>\n",
       "      <td>Oil &amp; gas</td>\n",
       "      <td>2008-02-19</td>\n",
       "      <td>also 1930-07-18 to 1999-11-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Cisco Systems</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>CSCO</td>\n",
       "      <td>Computer networking</td>\n",
       "      <td>2009-06-08</td>\n",
       "      <td>Dropped from Dow Jones as of January 5, 1912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Coca-Cola</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>KO</td>\n",
       "      <td>Beverages</td>\n",
       "      <td>1987-03-12</td>\n",
       "      <td>also 1932-05-26 to 1935-11-20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DuPont</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>DD</td>\n",
       "      <td>Chemical industry</td>\n",
       "      <td>1935-11-20</td>\n",
       "      <td>also 1924-01-22 to 1925-08-31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ExxonMobil</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>XOM</td>\n",
       "      <td>Oil &amp; gas</td>\n",
       "      <td>1928-10-01</td>\n",
       "      <td>as Standard Oil of New Jersey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>General Electric</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>GE</td>\n",
       "      <td>Conglomerate</td>\n",
       "      <td>1907-11-07</td>\n",
       "      <td>also 1896-05-26 to 1898-10 and 1899-04-21 to 1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Goldman Sachs</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>GS</td>\n",
       "      <td>Banking, Financial services</td>\n",
       "      <td>2013-09-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The Home Depot</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>HD</td>\n",
       "      <td>Home improvement retailer</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>IBM</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>IBM</td>\n",
       "      <td>Computers and technology</td>\n",
       "      <td>1979-06-29</td>\n",
       "      <td>also 1932-05-26 to 1939-03-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Intel</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>INTC</td>\n",
       "      <td>Semiconductors</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Johnson &amp; Johnson</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>JNJ</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>1997-03-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>JPMorgan Chase</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>JPM</td>\n",
       "      <td>Banking</td>\n",
       "      <td>1991-05-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>McDonald's</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>MCD</td>\n",
       "      <td>Fast food</td>\n",
       "      <td>1985-10-30</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Merck</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>MRK</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>1979-06-29</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Microsoft</td>\n",
       "      <td>NASDAQ</td>\n",
       "      <td>MSFT</td>\n",
       "      <td>Software</td>\n",
       "      <td>1999-11-01</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Nike</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>NKE</td>\n",
       "      <td>Apparel</td>\n",
       "      <td>2013-09-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Pfizer</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>PFE</td>\n",
       "      <td>Pharmaceuticals</td>\n",
       "      <td>2004-04-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>Procter &amp; Gamble</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>PG</td>\n",
       "      <td>Consumer goods</td>\n",
       "      <td>1932-05-26</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Travelers</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>TRV</td>\n",
       "      <td>Insurance</td>\n",
       "      <td>2009-06-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>UnitedHealth Group</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>UNH</td>\n",
       "      <td>Managed health care</td>\n",
       "      <td>2012-09-24</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>United Technologies</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>UTX</td>\n",
       "      <td>Conglomerate</td>\n",
       "      <td>1939-03-14</td>\n",
       "      <td>as United Aircraft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Verizon</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>VZ</td>\n",
       "      <td>Telecommunication</td>\n",
       "      <td>2004-04-08</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Visa</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>V</td>\n",
       "      <td>Consumer banking</td>\n",
       "      <td>2013-09-20</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Wal-Mart</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>WMT</td>\n",
       "      <td>Retail</td>\n",
       "      <td>1997-03-17</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>Walt Disney</td>\n",
       "      <td>NYSE</td>\n",
       "      <td>DIS</td>\n",
       "      <td>Broadcasting and entertainment</td>\n",
       "      <td>1991-05-06</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                Company Exchange Symbol                           Industry  \\\n",
       "0                    3M     NYSE    MMM                       Conglomerate   \n",
       "1      American Express     NYSE    AXP                   Consumer finance   \n",
       "2                 Apple   NASDAQ   AAPL               Consumer electronics   \n",
       "3                Boeing     NYSE     BA              Aerospace and defense   \n",
       "4           Caterpillar     NYSE    CAT  Construction and mining equipment   \n",
       "5               Chevron     NYSE    CVX                          Oil & gas   \n",
       "6         Cisco Systems   NASDAQ   CSCO                Computer networking   \n",
       "7             Coca-Cola     NYSE     KO                          Beverages   \n",
       "8                DuPont     NYSE     DD                  Chemical industry   \n",
       "9            ExxonMobil     NYSE    XOM                          Oil & gas   \n",
       "10     General Electric     NYSE     GE                       Conglomerate   \n",
       "11        Goldman Sachs     NYSE     GS        Banking, Financial services   \n",
       "12       The Home Depot     NYSE     HD          Home improvement retailer   \n",
       "13                  IBM     NYSE    IBM           Computers and technology   \n",
       "14                Intel     NYSE   INTC                     Semiconductors   \n",
       "15    Johnson & Johnson     NYSE    JNJ                    Pharmaceuticals   \n",
       "16       JPMorgan Chase     NYSE    JPM                            Banking   \n",
       "17           McDonald's     NYSE    MCD                          Fast food   \n",
       "18                Merck     NYSE    MRK                    Pharmaceuticals   \n",
       "19            Microsoft   NASDAQ   MSFT                           Software   \n",
       "20                 Nike     NYSE    NKE                            Apparel   \n",
       "21               Pfizer     NYSE    PFE                    Pharmaceuticals   \n",
       "22     Procter & Gamble     NYSE     PG                     Consumer goods   \n",
       "23            Travelers     NYSE    TRV                          Insurance   \n",
       "24   UnitedHealth Group     NYSE    UNH                Managed health care   \n",
       "25  United Technologies     NYSE    UTX                       Conglomerate   \n",
       "26              Verizon     NYSE     VZ                  Telecommunication   \n",
       "27                 Visa     NYSE      V                   Consumer banking   \n",
       "28             Wal-Mart     NYSE    WMT                             Retail   \n",
       "29          Walt Disney     NYSE    DIS     Broadcasting and entertainment   \n",
       "\n",
       "    Date Added                                              Notes  \n",
       "0   1976-08-09              as Minnesota Mining and Manufacturing  \n",
       "1   1982-08-30                                                NaN  \n",
       "2   2015-03-19                                                NaN  \n",
       "3   1987-03-12                                                NaN  \n",
       "4   1991-05-06                                                NaN  \n",
       "5   2008-02-19                      also 1930-07-18 to 1999-11-01  \n",
       "6   2009-06-08       Dropped from Dow Jones as of January 5, 1912  \n",
       "7   1987-03-12                      also 1932-05-26 to 1935-11-20  \n",
       "8   1935-11-20                      also 1924-01-22 to 1925-08-31  \n",
       "9   1928-10-01                      as Standard Oil of New Jersey  \n",
       "10  1907-11-07  also 1896-05-26 to 1898-10 and 1899-04-21 to 1...  \n",
       "11  2013-09-20                                                NaN  \n",
       "12  1999-11-01                                                NaN  \n",
       "13  1979-06-29                      also 1932-05-26 to 1939-03-04  \n",
       "14  1999-11-01                                                NaN  \n",
       "15  1997-03-17                                                NaN  \n",
       "16  1991-05-06                                                NaN  \n",
       "17  1985-10-30                                                NaN  \n",
       "18  1979-06-29                                                NaN  \n",
       "19  1999-11-01                                                NaN  \n",
       "20  2013-09-20                                                NaN  \n",
       "21  2004-04-08                                                NaN  \n",
       "22  1932-05-26                                                NaN  \n",
       "23  2009-06-08                                                NaN  \n",
       "24  2012-09-24                                                NaN  \n",
       "25  1939-03-14                                 as United Aircraft  \n",
       "26  2004-04-08                                                NaN  \n",
       "27  2013-09-20                                                NaN  \n",
       "28  1997-03-17                                                NaN  \n",
       "29  1991-05-06                                                NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tables[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Использование HTTP API\n",
    "\n",
    "Примеры API:\n",
    " - Яндекс Карты\n",
    " - "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/site-packages/requests/packages/urllib3/util/ssl_.py:120: InsecurePlatformWarning: A true SSLContext object is not available. This prevents urllib3 from configuring SSL appropriately and may cause certain SSL connections to fail. For more information, see https://urllib3.readthedocs.org/en/latest/security.html#insecureplatformwarning.\n",
      "  InsecurePlatformWarning\n"
     ]
    }
   ],
   "source": [
    "resp = requests.get(\n",
    "    'https://geocode-maps.yandex.ru/1.x/',\n",
    "    params={'format': 'json', 'geocode': 'Масква Тверская улца дом 7'},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "found = resp.json()['response']['GeoObjectCollection']['featureMember'][0]['GeoObject']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"metaDataProperty\": {\n",
      "    \"GeocoderMetaData\": {\n",
      "      \"text\": \"Россия, Москва, Тверская улица, 7\", \n",
      "      \"kind\": \"house\", \n",
      "      \"AddressDetails\": {\n",
      "        \"Country\": {\n",
      "          \"CountryName\": \"Россия\", \n",
      "          \"AdministrativeArea\": {\n",
      "            \"AdministrativeAreaName\": \"Москва\", \n",
      "            \"Locality\": {\n",
      "              \"Thoroughfare\": {\n",
      "                \"Premise\": {\n",
      "                  \"PremiseNumber\": \"7\"\n",
      "                }, \n",
      "                \"ThoroughfareName\": \"Тверская улица\"\n",
      "              }, \n",
      "              \"LocalityName\": \"Москва\"\n",
      "            }\n",
      "          }, \n",
      "          \"AddressLine\": \"Москва, Тверская улица, 7\", \n",
      "          \"CountryNameCode\": \"RU\"\n",
      "        }\n",
      "      }, \n",
      "      \"precision\": \"exact\"\n",
      "    }\n",
      "  }, \n",
      "  \"boundedBy\": {\n",
      "    \"Envelope\": {\n",
      "      \"upperCorner\": \"37.619234 55.762601\", \n",
      "      \"lowerCorner\": \"37.602777 55.753321\"\n",
      "    }\n",
      "  }, \n",
      "  \"Point\": {\n",
      "    \"pos\": \"37.611006 55.757962\"\n",
      "  }, \n",
      "  \"description\": \"Москва, Россия\", \n",
      "  \"name\": \"Тверская улица, 7\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "print json.dumps(found, indent=2, encoding='utf8', ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Извлечение данных со страниц\n",
    "\n",
    "- [Scrapy](http://scrapy.org/)\n",
    "- [Пример работы с селекторами](http://doc.scrapy.org/en/1.0/topics/selectors.html)\n",
    "- простая документация по css селекторам"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-01c6f68e5155>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mresp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'https://www.hse.ru/staff/arjanstev'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "resp = requests.get('https://www.hse.ru/staff/arjanstev')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "page = scrapy.Selector(text=resp.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "u'<dl class=\"main-list large main-list-language-knowledge-level\"><dt class=\"b\">\\u0412\\u043b\\u0430\\u0434\\u0435\\u043d\\u0438\\u0435 \\u044f\\u0437\\u044b\\u043a\\u0430\\u043c\\u0438</dt><dd>\\u0430\\u043d\\u0433\\u043b\\u0438\\u0439\\u0441\\u043a\\u0438\\u0439</dd><dd>\\u0443\\u043a\\u0440\\u0430\\u0438\\u043d\\u0441\\u043a\\u0438\\u0439</dd><dd>\\u043d\\u0435\\u043c\\u0435\\u0446\\u043a\\u0438\\u0439</dd><dd>\\u0444\\u0440\\u0430\\u043d\\u0446\\u0443\\u0437\\u0441\\u043a\\u0438\\u0439</dd></dl>'"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page.css('dl.main-list-language-knowledge-level').extract_first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "английский\n",
      "украинский\n",
      "немецкий\n",
      "французский\n"
     ]
    }
   ],
   "source": [
    "langs = page.css('dl.main-list-language-knowledge-level dd ::text').extract()\n",
    "for lang in langs:\n",
    "    print lang"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Таблица из набора JSON-записей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   x  y\n",
       "0  1  a\n",
       "1  2  b\n",
       "2  3  a\n",
       "3  4  b"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pandas.DataFrame({\n",
    "        'x': [1, 2, 3, 4],\n",
    "        'y': ['a', 'b', 'a', 'b']\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pandas' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-83c16842bb41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m pandas.DataFrame([\n\u001b[0m\u001b[1;32m      2\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'a'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m         \u001b[0;34m{\u001b[0m\u001b[0;34m'x'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'y'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'b'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     ])\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pandas' is not defined"
     ]
    }
   ],
   "source": [
    "pandas.DataFrame.from_records([\n",
    "        {'x': 1, 'y': 'a'},\n",
    "        {'x': 2, 'y': 'b'}\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Машинное обучение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Предобработка данных, извлечение признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.arange(X.shape[0])\n",
    "np.random.shuffle(ids)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модели машинного обучения\n",
    "\n",
    "### Линейные модели\n",
    "\n",
    "### Деревья, композиции, бустинг"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценка качества моделей"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Метрики"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Кросс-валидация"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import ShuffleSplit, KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cv = KFold(data.shape[0], n_folds=10, shuffle=True, random_state=123)\n",
    "importances = []\n",
    "aucs = []\n",
    "for train_ids, test_ids in tqdm(cv):\n",
    "    dtrain = xgb.DMatrix(data.iloc[train_ids, :][features].values, label=data.iloc[train_ids, :][target].values)\n",
    "    dtest = xgb.DMatrix(data.iloc[test_ids, :][features].values, label=data.iloc[test_ids, :][target].values)\n",
    "    \n",
    "    param = {'bst:max_depth':6, 'bst:eta':0.05, 'objective':'binary:logistic' }\n",
    "    param['eval_metric'] = 'auc'\n",
    "\n",
    "    evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "    num_round = 300\n",
    "    bst = xgb.train(param, dtrain, num_round)\n",
    "    preds = bst.predict(dtest)\n",
    "    aucs.append(roc_auc_score(data.iloc[test_ids, :][target].values, preds))\n",
    "    importances.append(bst.get_fscore())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ids = np.arange(data.shape[0])\n",
    "np.random.shuffle(ids)\n",
    "info = ['duration',\n",
    "        'tower_status_radiant',\n",
    "        'tower_status_dire',\n",
    "        'barracks_status_radiant',\n",
    "        'barracks_status_dire']\n",
    "features = filter(lambda s: s != 'radiant_win' and s not in info, data.columns)\n",
    "target = ['radiant_win']\n",
    "\n",
    "dtrain = xgb.DMatrix(data.loc[:,features].values[ids[10000:],:], label=data.loc[:,target].values[ids[10000:],:])\n",
    "dtest = xgb.DMatrix(data.loc[:,features].values[ids[:10000],:], label=data.loc[:,target].values[ids[:10000],:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "param = {'bst:max_depth':6, 'bst:eta':0.05, 'objective':'binary:logistic' }\n",
    "param['eval_metric'] = 'auc'\n",
    "\n",
    "evallist  = [(dtest,'eval'), (dtrain,'train')]\n",
    "num_round = 300\n",
    "bst = xgb.train(param, dtrain, num_round, evallist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "figsize(16,6)\n",
    "n_top = 30\n",
    "\n",
    "f_score = sorted(bst.get_fscore().items(), key=lambda i: i[1], reverse=True)\n",
    "ids = np.arange(n_top)\n",
    "labels = [k[0] for k in f_score]\n",
    "labels = np.array(features)[map(lambda s: int(s[1:]), labels)[:n_top]]\n",
    "values = [k[1] for k in f_score]\n",
    "plt.xticks(ids, labels[:n_top], rotation=45)\n",
    "plt.title('feature importances', size=20)\n",
    "plt.plot(ids, values[:n_top])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
